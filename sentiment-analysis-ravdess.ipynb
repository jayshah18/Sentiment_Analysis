{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13645900,"sourceType":"datasetVersion","datasetId":8674652}],"dockerImageVersionId":31193,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/shahjaysuhasbhai/sentiment-analysis-from-audio-ravdess-dataset?scriptVersionId=275802244\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-11T06:05:13.804551Z","iopub.execute_input":"2025-11-11T06:05:13.804784Z","iopub.status.idle":"2025-11-11T06:05:16.688768Z","shell.execute_reply.started":"2025-11-11T06:05:13.80476Z","shell.execute_reply":"2025-11-11T06:05:16.688025Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as  np","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T06:05:16.690268Z","iopub.execute_input":"2025-11-11T06:05:16.690595Z","iopub.status.idle":"2025-11-11T06:05:16.693999Z","shell.execute_reply.started":"2025-11-11T06:05:16.690572Z","shell.execute_reply":"2025-11-11T06:05:16.693086Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport librosa\n\ndef review_dataset(dataset_path):\n    total_files = 0\n    summary = {}\n\n    for actor_folder in sorted(os.listdir(dataset_path)):\n        actor_path = os.path.join(dataset_path, actor_folder)\n        if os.path.isdir(actor_path):\n            file_list = [f for f in os.listdir(actor_path) if f.endswith(\".wav\") or f.endswith(\".mp3\")]\n            total_files += len(file_list)\n\n            durations = []\n            for file in file_list:\n                file_path = os.path.join(actor_path, file)\n                signal, sr = librosa.load(file_path, sr=None)\n                durations.append(librosa.get_duration(y=signal, sr=sr))\n\n            summary[actor_folder] = {\n                \"file_count\": len(file_list),\n                \"avg_duration_sec\": round(sum(durations)/len(durations), 2) if durations else 0\n            }\n\n    print(f\"\\n✅ Total Actors: {len(summary)}\")\n    print(f\"✅ Total Audio Files: {total_files}\\n\")\n\n    for actor, stats in summary.items():\n        print(f\"{actor}: {stats['file_count']} files | Avg Duration: {stats['avg_duration_sec']} sec\")\n\n# Run this\nreview_dataset(\"/kaggle/input/ravdess-audio-only/DATASET\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T06:05:26.6255Z","iopub.execute_input":"2025-11-11T06:05:26.626144Z","iopub.status.idle":"2025-11-11T06:05:54.717804Z","shell.execute_reply.started":"2025-11-11T06:05:26.626123Z","shell.execute_reply":"2025-11-11T06:05:54.717019Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\ndef create_dataset_dataframe(dataset_path):\n    \"\"\"\n    Parses the RAVDESS dataset filenames to create a structured DataFrame.\n\n    The RAVDESS filename consists of a 7-part numerical identifier (e.g., 03-01-01-01-01-01-01.wav).\n    The 3rd part identifies the emotion.\n\n    Args:\n        dataset_path (str): The root path to the RAVDESS dataset (e.g., '/content/drive/MyDrive/DATASET').\n\n    Returns:\n        pandas.DataFrame: A DataFrame with columns for filepath, actor, and emotion.\n    \"\"\"\n\n    # Emotion labels mapping from the RAVDESS documentation\n    emotion_map = {\n        \"01\": \"neutral\",\n        \"02\": \"calm\",\n        \"03\": \"happy\",\n        \"04\": \"sad\",\n        \"05\": \"angry\",\n        \"06\": \"fearful\",\n        \"07\": \"disgust\",\n        \"08\": \"surprised\"\n    }\n\n    data = []\n\n    print(f\"Parsing dataset from: {dataset_path}\")\n\n    for actor_folder in sorted(os.listdir(dataset_path)):\n        actor_path = os.path.join(dataset_path, actor_folder)\n        if os.path.isdir(actor_path):\n            for file_name in os.listdir(actor_path):\n                if file_name.endswith(\".wav\"):\n                    parts = file_name.split(\".\")[0].split(\"-\")\n\n                    # Ensure the filename has the correct number of parts\n                    if len(parts) == 7:\n                        emotion_code = parts[2]\n                        actor_id = parts[6]\n                        file_path = os.path.join(actor_path, file_name)\n\n                        # Get the emotion label from the map\n                        emotion_label = emotion_map.get(emotion_code)\n\n                        if emotion_label:\n                            data.append({\n                                \"filepath\": file_path,\n                                \"actor\": actor_id,\n                                \"emotion\": emotion_label\n                            })\n                        else:\n                            print(f\"Warning: Unknown emotion code '{emotion_code}' in file {file_name}\")\n\n    if not data:\n        print(\"\\nError: No data was loaded. Please check the following:\")\n        print(f\"1. Does the path '{dataset_path}' exist?\")\n        print(\"2. Is it the correct root folder containing the 'Actor_01', 'Actor_02', etc. subfolders?\")\n        return None\n\n    # Create a DataFrame\n    df = pd.DataFrame(data)\n    print(f\"\\n✅ Successfully created DataFrame with {len(df)} entries.\")\n    return df\n\n# --- HOW TO RUN THIS SCRIPT ---\n# 1. Make sure pandas is installed: pip install pandas\n# 2. Update the dataset_path to your actual path\n# 3. Run the script\n\nif __name__ == '__main__':\n    dataset_path = \"/kaggle/input/ravdess-audio-only/DATASET\"\n    ravdess_df = create_dataset_dataframe(dataset_path)\n\n    if ravdess_df is not None:\n        # Display the first few rows of the DataFrame\n        print(\"\\n--- DataFrame Head ---\")\n        print(ravdess_df.head())\n\n        # Display the distribution of emotions\n        print(\"\\n--- Emotion Distribution ---\")\n        print(ravdess_df['emotion'].value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T06:05:58.209489Z","iopub.execute_input":"2025-11-11T06:05:58.20991Z","iopub.status.idle":"2025-11-11T06:05:58.251828Z","shell.execute_reply.started":"2025-11-11T06:05:58.209886Z","shell.execute_reply":"2025-11-11T06:05:58.251251Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tqdm import tqdm\n\ndef create_dataset_dataframe(dataset_path):\n    \"\"\"\n    Parses the RAVDESS dataset filenames to create a structured DataFrame.\n    This is the same function from the previous script.\n    \"\"\"\n    emotion_map = {\n        \"01\": \"neutral\", \"02\": \"calm\", \"03\": \"happy\", \"04\": \"sad\",\n        \"05\": \"angry\", \"06\": \"fearful\", \"07\": \"disgust\", \"08\": \"surprised\"\n    }\n    data = []\n    print(f\"Parsing dataset from: {dataset_path}\")\n    for actor_folder in sorted(os.listdir(dataset_path)):\n        actor_path = os.path.join(dataset_path, actor_folder)\n        if os.path.isdir(actor_path):\n            for file_name in os.listdir(actor_path):\n                if file_name.endswith(\".wav\"):\n                    parts = file_name.split(\".\")[0].split(\"-\")\n                    if len(parts) == 7:\n                        emotion_code = parts[2]\n                        actor_id = parts[6]\n                        file_path = os.path.join(actor_path, file_name)\n                        emotion_label = emotion_map.get(emotion_code)\n                        if emotion_label:\n                            data.append({\n                                \"filepath\": file_path,\n                                \"actor\": actor_id,\n                                \"emotion\": emotion_label\n                            })\n    if not data:\n        print(\"\\nError: No data was loaded.\")\n        return None\n    df = pd.DataFrame(data)\n    print(f\"\\n✅ Successfully created DataFrame with {len(df)} entries.\")\n    return df\n\ndef extract_features(file_path):\n    \"\"\"\n    Extracts Mel Spectrogram and aggregated features (MFCC, Chroma, ZCR) from an audio file.\n    \"\"\"\n    try:\n        # Load audio file at a consistent sample rate\n        signal, sample_rate = librosa.load(file_path, sr=22050)\n\n        # --- Features for Deep Learning Models (CNN, LSTM) ---\n        # Mel Spectrogram (for CNNs)\n        mel_spectrogram = librosa.feature.melspectrogram(y=signal, sr=sample_rate, n_mels=128)\n\n        # --- Features for Traditional ML Models (SVM, Random Forest) ---\n        # MFCCs, Chroma, Zero-Crossing Rate\n        mfccs = librosa.feature.mfcc(y=signal, sr=sample_rate, n_mfcc=40)\n        chroma = librosa.feature.chroma_stft(y=signal, sr=sample_rate)\n        zcr = librosa.feature.zero_crossing_rate(y=signal)\n\n        # Aggregate features by taking the mean across time\n        mfccs_mean = np.mean(mfccs, axis=1)\n        chroma_mean = np.mean(chroma, axis=1)\n        zcr_mean = np.mean(zcr, axis=1)\n\n        # Combine aggregated features into a single feature vector\n        aggregated_features = np.hstack([mfccs_mean, chroma_mean, zcr_mean])\n\n        return mel_spectrogram, aggregated_features\n\n    except Exception as e:\n        print(f\"Error processing {file_path}: {e}\")\n        return None, None\n\n\n# --- HOW TO RUN THIS SCRIPT ---\n# 1. Make sure pandas, librosa, numpy, and tqdm are installed.\n#    pip install pandas librosa numpy tqdm\n# 2. Update the dataset_path.\n# 3. Run the script. It will save a 'features_dataframe.pkl' file.\n\nif __name__ == '__main__':\n    # Initialize tqdm to work with pandas .apply()\n    tqdm.pandas()\n\n    dataset_path = \"//kaggle/input/ravdess-audio-only/DATASET\"\n    ravdess_df = create_dataset_dataframe(dataset_path)\n\n    if ravdess_df is not None:\n        print(\"\\nExtracting features from audio files... (This may take a few minutes)\")\n\n        # Apply the feature extraction function to each file\n        # The result of the lambda function is a tuple, which pandas expands into two new columns\n        ravdess_df[['mel_spectrogram', 'aggregated_features']] = ravdess_df['filepath'].progress_apply(\n            lambda filepath: pd.Series(extract_features(filepath))\n        )\n\n        # Drop rows where feature extraction might have failed\n        ravdess_df.dropna(inplace=True)\n\n        # Save the feature-rich dataframe to a pickle file for quick loading later\n        output_path = \"features_dataframe.pkl\"\n        ravdess_df.to_pickle(output_path)\n\n        print(f\"\\n✅ Feature extraction complete.\")\n        print(f\"✅ DataFrame saved to '{output_path}'\")\n        print(\"\\n--- DataFrame Head with New Features ---\")\n        print(ravdess_df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T06:06:01.339605Z","iopub.execute_input":"2025-11-11T06:06:01.340165Z","iopub.status.idle":"2025-11-11T06:06:50.27228Z","shell.execute_reply.started":"2025-11-11T06:06:01.340142Z","shell.execute_reply":"2025-11-11T06:06:50.271494Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ravdess_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T03:12:20.036337Z","iopub.execute_input":"2025-11-11T03:12:20.036914Z","iopub.status.idle":"2025-11-11T03:12:20.335177Z","shell.execute_reply.started":"2025-11-11T03:12:20.036889Z","shell.execute_reply":"2025-11-11T03:12:20.334277Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ravdess_df.isnull().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T03:12:23.519727Z","iopub.execute_input":"2025-11-11T03:12:23.520511Z","iopub.status.idle":"2025-11-11T03:12:23.528283Z","shell.execute_reply.started":"2025-11-11T03:12:23.520474Z","shell.execute_reply":"2025-11-11T03:12:23.527594Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Checking accuracy using SVC and Random Forest seperately","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T03:12:27.976133Z","iopub.execute_input":"2025-11-11T03:12:27.976444Z","iopub.status.idle":"2025-11-11T03:12:28.743888Z","shell.execute_reply.started":"2025-11-11T03:12:27.976421Z","shell.execute_reply":"2025-11-11T03:12:28.743335Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X = np.array(ravdess_df['aggregated_features'].tolist())\ny = ravdess_df['emotion']\nlabel_encoder = LabelEncoder()\ny_encoded = label_encoder.fit_transform(y)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T03:12:29.863006Z","iopub.execute_input":"2025-11-11T03:12:29.86368Z","iopub.status.idle":"2025-11-11T03:12:29.86995Z","shell.execute_reply.started":"2025-11-11T03:12:29.863659Z","shell.execute_reply":"2025-11-11T03:12:29.869206Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- Actor-Independent Split ---\n# This is the most important step for a fair evaluation.\n# We split based on actor IDs, not random rows.\n\n# actor_ids = ravdess_df['actor'].unique()\n# train_actors, test_actors = train_test_split(actor_ids, test_size=0.15, random_state=42)\n# train_actors, val_actors = train_test_split(train_actors, test_size=(0.15/0.85), random_state=42) # 0.15/0.85 is ~17.6% of the 85%\n\n# # Create the data splits based on actor IDs\n# train_indices = ravdess_df['actor'].isin(train_actors)\n# val_indices = ravdess_df['actor'].isin(val_actors)\n# test_indices = ravdess_df['actor'].isin(test_actors)\n\n# X_train, y_train = X[train_indices], y_encoded[train_indices]\n# X_val, y_val = X[val_indices], y_encoded[val_indices]\n# X_test, y_test = X[test_indices], y_encoded[test_indices]\n\n\nactor_ids = ravdess_df['actor'].unique()\n\n# Split actors into train and test only\ntrain_actors, test_actors = train_test_split(\n    actor_ids,\n    test_size=0.15,    # 15% of actors for testing\n    random_state=42\n)\n\n# Create boolean masks\ntrain_indices = ravdess_df['actor'].isin(train_actors)\ntest_indices = ravdess_df['actor'].isin(test_actors)\n\n# Create final datasets\nX_train, y_train = X[train_indices], y_encoded[train_indices]\nX_test, y_test = X[test_indices], y_encoded[test_indices]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T03:12:32.668218Z","iopub.execute_input":"2025-11-11T03:12:32.66883Z","iopub.status.idle":"2025-11-11T03:12:32.680377Z","shell.execute_reply.started":"2025-11-11T03:12:32.668806Z","shell.execute_reply":"2025-11-11T03:12:32.679585Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"scaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T03:12:32.978865Z","iopub.execute_input":"2025-11-11T03:12:32.979625Z","iopub.status.idle":"2025-11-11T03:12:32.989406Z","shell.execute_reply.started":"2025-11-11T03:12:32.979603Z","shell.execute_reply":"2025-11-11T03:12:32.988736Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Support Vector Machine","metadata":{}},{"cell_type":"code","source":"svm_model = SVC(kernel='rbf', C=4)\nsvm_model.fit(X_train_scaled, y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T03:12:44.521187Z","iopub.execute_input":"2025-11-11T03:12:44.521827Z","iopub.status.idle":"2025-11-11T03:12:44.665202Z","shell.execute_reply.started":"2025-11-11T03:12:44.521801Z","shell.execute_reply":"2025-11-11T03:12:44.664596Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"svm_predictions = svm_model.predict(X_test_scaled)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T03:12:46.817216Z","iopub.execute_input":"2025-11-11T03:12:46.817505Z","iopub.status.idle":"2025-11-11T03:12:46.846999Z","shell.execute_reply.started":"2025-11-11T03:12:46.817485Z","shell.execute_reply":"2025-11-11T03:12:46.846492Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(y_test, svm_predictions))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T03:12:48.757243Z","iopub.execute_input":"2025-11-11T03:12:48.757536Z","iopub.status.idle":"2025-11-11T03:12:48.768536Z","shell.execute_reply.started":"2025-11-11T03:12:48.75751Z","shell.execute_reply":"2025-11-11T03:12:48.767926Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Random Forest","metadata":{}},{"cell_type":"code","source":"rf_model = RandomForestClassifier(n_estimators=300,criterion='entropy', max_depth=20, random_state=42)\nrf_model.fit(X_train_scaled, y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T03:12:52.855248Z","iopub.execute_input":"2025-11-11T03:12:52.855873Z","iopub.status.idle":"2025-11-11T03:12:56.773785Z","shell.execute_reply.started":"2025-11-11T03:12:52.855849Z","shell.execute_reply":"2025-11-11T03:12:56.773028Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"rf_predictions = rf_model.predict(X_test_scaled)\nprint(\"Random Forest Classification Report\")\nprint(classification_report(y_test, rf_predictions, target_names=label_encoder.classes_))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T03:12:58.966255Z","iopub.execute_input":"2025-11-11T03:12:58.966544Z","iopub.status.idle":"2025-11-11T03:12:59.000134Z","shell.execute_reply.started":"2025-11-11T03:12:58.966523Z","shell.execute_reply":"2025-11-11T03:12:58.999527Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Voting for using both models with better accuracy","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import VotingClassifier\nestimators = [('SVC', svm_model), ('RF', rf_model)]\nvc = VotingClassifier(estimators = estimators)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T03:13:06.450146Z","iopub.execute_input":"2025-11-11T03:13:06.45044Z","iopub.status.idle":"2025-11-11T03:13:06.454589Z","shell.execute_reply.started":"2025-11-11T03:13:06.450416Z","shell.execute_reply":"2025-11-11T03:13:06.453881Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"vc.fit(X_train, y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T03:13:13.044244Z","iopub.execute_input":"2025-11-11T03:13:13.044979Z","iopub.status.idle":"2025-11-11T03:13:16.981356Z","shell.execute_reply.started":"2025-11-11T03:13:13.044953Z","shell.execute_reply":"2025-11-11T03:13:16.980713Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(vc.score(X_test_scaled, y_test))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T03:20:13.307497Z","iopub.execute_input":"2025-11-11T03:20:13.308241Z","iopub.status.idle":"2025-11-11T03:20:13.360025Z","shell.execute_reply.started":"2025-11-11T03:20:13.308208Z","shell.execute_reply":"2025-11-11T03:20:13.359461Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Since we have <40% of accuracy for each model, we are getting worse when we combine them using voting classifier","metadata":{}},{"cell_type":"markdown","source":"## Bagging","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import BaggingClassifier","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T03:14:32.038367Z","iopub.execute_input":"2025-11-11T03:14:32.039024Z","iopub.status.idle":"2025-11-11T03:14:32.042248Z","shell.execute_reply.started":"2025-11-11T03:14:32.039002Z","shell.execute_reply":"2025-11-11T03:14:32.041561Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T03:17:05.6154Z","iopub.execute_input":"2025-11-11T03:17:05.616016Z","iopub.status.idle":"2025-11-11T03:17:05.619393Z","shell.execute_reply.started":"2025-11-11T03:17:05.61599Z","shell.execute_reply":"2025-11-11T03:17:05.618609Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"bag = BaggingClassifier(\n    estimator = DecisionTreeClassifier(),\n    n_estimators = 500,\n    max_samples = 0.25,\n    bootstrap = True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T03:17:25.099899Z","iopub.execute_input":"2025-11-11T03:17:25.100454Z","iopub.status.idle":"2025-11-11T03:17:25.104064Z","shell.execute_reply.started":"2025-11-11T03:17:25.100431Z","shell.execute_reply":"2025-11-11T03:17:25.103446Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"bag.fit(X_train_scaled, y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T03:17:51.958078Z","iopub.execute_input":"2025-11-11T03:17:51.958844Z","iopub.status.idle":"2025-11-11T03:17:57.559964Z","shell.execute_reply.started":"2025-11-11T03:17:51.958819Z","shell.execute_reply":"2025-11-11T03:17:57.559351Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_pred = bag.predict(X_test_scaled)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T03:20:25.620328Z","iopub.execute_input":"2025-11-11T03:20:25.620921Z","iopub.status.idle":"2025-11-11T03:20:25.697156Z","shell.execute_reply.started":"2025-11-11T03:20:25.620899Z","shell.execute_reply":"2025-11-11T03:20:25.696348Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nprint(accuracy_score(y_test, y_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T03:21:28.593924Z","iopub.execute_input":"2025-11-11T03:21:28.594196Z","iopub.status.idle":"2025-11-11T03:21:28.599923Z","shell.execute_reply.started":"2025-11-11T03:21:28.594176Z","shell.execute_reply":"2025-11-11T03:21:28.599079Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nparameters = {\n    'n_estimators' : [300, 400, 500],\n    'max_samples' : [0.1,0.25,0.5,0.75],\n    'bootstrap' : [True, False],\n}\nsearch = GridSearchCV(\n    estimator=bag,\n    param_grid=parameters,\n    cv=5\n)\nsearch.fit(X_train, y_train)\nsearch.best_params_","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T03:40:49.523564Z","iopub.execute_input":"2025-11-11T03:40:49.524079Z","iopub.status.idle":"2025-11-11T03:53:17.822174Z","shell.execute_reply.started":"2025-11-11T03:40:49.524053Z","shell.execute_reply":"2025-11-11T03:53:17.821241Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"bag = BaggingClassifier(\n    estimator = DecisionTreeClassifier(),\n    n_estimators = 300,\n    max_samples = 0.1,\n    bootstrap = True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T03:53:31.935079Z","iopub.execute_input":"2025-11-11T03:53:31.935372Z","iopub.status.idle":"2025-11-11T03:53:31.93911Z","shell.execute_reply.started":"2025-11-11T03:53:31.935352Z","shell.execute_reply":"2025-11-11T03:53:31.938421Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"bag.fit(X_train_scaled, y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T03:53:34.972942Z","iopub.execute_input":"2025-11-11T03:53:34.973545Z","iopub.status.idle":"2025-11-11T03:53:36.416077Z","shell.execute_reply.started":"2025-11-11T03:53:34.973517Z","shell.execute_reply":"2025-11-11T03:53:36.41547Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_pred = bag.predict(X_test_scaled)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T03:53:38.551738Z","iopub.execute_input":"2025-11-11T03:53:38.552322Z","iopub.status.idle":"2025-11-11T03:53:38.598514Z","shell.execute_reply.started":"2025-11-11T03:53:38.552276Z","shell.execute_reply":"2025-11-11T03:53:38.597975Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(accuracy_score(y_test, y_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T03:53:40.579192Z","iopub.execute_input":"2025-11-11T03:53:40.580018Z","iopub.status.idle":"2025-11-11T03:53:40.584987Z","shell.execute_reply.started":"2025-11-11T03:53:40.579985Z","shell.execute_reply":"2025-11-11T03:53:40.584184Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Have to use neural network","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T03:55:43.831709Z","iopub.execute_input":"2025-11-11T03:55:43.832443Z","iopub.status.idle":"2025-11-11T03:55:43.835635Z","shell.execute_reply.started":"2025-11-11T03:55:43.832411Z","shell.execute_reply":"2025-11-11T03:55:43.835042Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## CNN","metadata":{}},{"cell_type":"code","source":"!pip install protobuf==3.20.*","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T03:56:57.425947Z","iopub.execute_input":"2025-11-11T03:56:57.426461Z","iopub.status.idle":"2025-11-11T03:57:00.518093Z","shell.execute_reply.started":"2025-11-11T03:56:57.426438Z","shell.execute_reply":"2025-11-11T03:57:00.517354Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\nfrom tensorflow.keras.utils import to_categorical\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T03:57:06.56875Z","iopub.execute_input":"2025-11-11T03:57:06.569474Z","iopub.status.idle":"2025-11-11T03:57:06.573056Z","shell.execute_reply.started":"2025-11-11T03:57:06.569448Z","shell.execute_reply":"2025-11-11T03:57:06.572348Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"frame_lengths = []\n\nfor mel in ravdess_df['mel_spectrogram'].tolist():    # list/array of mel spectrograms\n    frame_lengths.append(mel.shape[1])\n\nimport matplotlib.pyplot as plt\n\nplt.hist(frame_lengths, bins=40)\nplt.title(\"Distribution of mel-spectrogram time frames\")\nplt.xlabel(\"Number of frames\")\nplt.ylabel(\"Count\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T03:57:09.695903Z","iopub.execute_input":"2025-11-11T03:57:09.696615Z","iopub.status.idle":"2025-11-11T03:57:10.050704Z","shell.execute_reply.started":"2025-11-11T03:57:09.696588Z","shell.execute_reply":"2025-11-11T03:57:10.050064Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"max_pad_len = int(np.percentile(frame_lengths, 95))\nprint(\"Recommended pad length:\", max_pad_len)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T03:57:14.004801Z","iopub.execute_input":"2025-11-11T03:57:14.005311Z","iopub.status.idle":"2025-11-11T03:57:14.010362Z","shell.execute_reply.started":"2025-11-11T03:57:14.005269Z","shell.execute_reply":"2025-11-11T03:57:14.00955Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# The CNN expects image-like data, so we use the mel_spectrograms\nX_spectrograms = ravdess_df['mel_spectrogram'].tolist()\nmax_pad_len = 186","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T03:57:15.695136Z","iopub.execute_input":"2025-11-11T03:57:15.695925Z","iopub.status.idle":"2025-11-11T03:57:15.699381Z","shell.execute_reply.started":"2025-11-11T03:57:15.695899Z","shell.execute_reply":"2025-11-11T03:57:15.698647Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def pad_spectrogram(spec, max_len):\n        if spec.shape[1] > max_len:\n            return spec[:, :max_len]\n        else:\n            padding = max_len - spec.shape[1]\n            return np.pad(spec, ((0, 0), (0, padding)), mode='constant')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T03:57:17.887428Z","iopub.execute_input":"2025-11-11T03:57:17.887712Z","iopub.status.idle":"2025-11-11T03:57:17.891993Z","shell.execute_reply.started":"2025-11-11T03:57:17.887688Z","shell.execute_reply":"2025-11-11T03:57:17.891438Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_padded = np.array([pad_spectrogram(s, max_pad_len) for s in X_spectrograms])\n\n# Add a 'channel' dimension for the CNN (like a grayscale image)\nX_reshaped = X_padded[..., np.newaxis]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T03:57:21.5738Z","iopub.execute_input":"2025-11-11T03:57:21.57408Z","iopub.status.idle":"2025-11-11T03:57:21.798133Z","shell.execute_reply.started":"2025-11-11T03:57:21.574059Z","shell.execute_reply":"2025-11-11T03:57:21.797538Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Actor Independent Split\nactor_ids = ravdess_df['actor'].unique()\ntrain_actors, test_actors = train_test_split(actor_ids, test_size=0.15, random_state=42)\ntrain_actors, val_actors = train_test_split(train_actors, test_size=(0.15/0.85), random_state=42)\n\ntrain_indices = ravdess_df['actor'].isin(train_actors)\nval_indices = ravdess_df['actor'].isin(val_actors)\ntest_indices = ravdess_df['actor'].isin(test_actors)\n\nX_train, y_train = X_reshaped[train_indices], y_encoded[train_indices]\nX_val, y_val = X_reshaped[val_indices], y_encoded[val_indices]\nX_test, y_test = X_reshaped[test_indices], y_encoded[test_indices]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T03:57:23.965525Z","iopub.execute_input":"2025-11-11T03:57:23.96622Z","iopub.status.idle":"2025-11-11T03:57:24.016655Z","shell.execute_reply.started":"2025-11-11T03:57:23.966196Z","shell.execute_reply":"2025-11-11T03:57:24.016034Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Defining a CNN model\nmodel = Sequential([\n    Conv2D(32, (3, 3), activation='relu', input_shape=X_train.shape[1:]),\n    MaxPooling2D((2, 2)),\n    Dropout(0.25),\n\n    Conv2D(64, (3, 3), activation='relu'),\n    MaxPooling2D((2, 2)),\n    Dropout(0.25),\n\n    Conv2D(128, (3, 3), activation='relu'),\n    MaxPooling2D((2, 2)),\n    Dropout(0.25),\n\n    Flatten(),\n    Dense(128, activation='relu'),\n    Dropout(0.5),\n    Dense(len(label_encoder.classes_), activation='softmax') # Output layer\n])\n\nmodel.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T03:57:25.038888Z","iopub.execute_input":"2025-11-11T03:57:25.039472Z","iopub.status.idle":"2025-11-11T03:57:28.746266Z","shell.execute_reply.started":"2025-11-11T03:57:25.039448Z","shell.execute_reply":"2025-11-11T03:57:28.745476Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T03:57:34.3338Z","iopub.execute_input":"2025-11-11T03:57:34.334415Z","iopub.status.idle":"2025-11-11T03:57:34.354102Z","shell.execute_reply.started":"2025-11-11T03:57:34.334389Z","shell.execute_reply":"2025-11-11T03:57:34.353598Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Training\nhistory = model.fit(X_train, y_train,\n                    epochs=80,\n                    validation_data=(X_val, y_val),\n                    batch_size=32,\n                    verbose=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T04:34:05.084737Z","iopub.execute_input":"2025-11-11T04:34:05.085575Z","iopub.status.idle":"2025-11-11T04:35:05.641003Z","shell.execute_reply.started":"2025-11-11T04:34:05.085543Z","shell.execute_reply":"2025-11-11T04:35:05.640451Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Evaluate the Model\nprint(\"\\n--- Evaluating CNN Model on Test Set ---\")\ntest_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=1)\nprint(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T04:35:14.768783Z","iopub.execute_input":"2025-11-11T04:35:14.769266Z","iopub.status.idle":"2025-11-11T04:35:15.02513Z","shell.execute_reply.started":"2025-11-11T04:35:14.769243Z","shell.execute_reply":"2025-11-11T04:35:15.024564Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_pred_probs = model.predict(X_test)\ny_pred = np.argmax(y_pred_probs, axis=1)\nprint(classification_report(y_test, y_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T04:35:16.542249Z","iopub.execute_input":"2025-11-11T04:35:16.54251Z","iopub.status.idle":"2025-11-11T04:35:16.727148Z","shell.execute_reply.started":"2025-11-11T04:35:16.542493Z","shell.execute_reply":"2025-11-11T04:35:16.726333Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# EPOCH VS ACCURACY\n# Plot training history\nplt.figure(figsize=(12, 5))\n\n# Accuracy plot\nplt.subplot(1, 2, 1)\nplt.plot(history.history['accuracy'], label='Training Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.title('Model Accuracy over Epochs')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.grid(True)\n\n# Loss plot\nplt.subplot(1, 2, 2)\nplt.plot(history.history['loss'], label='Training Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.title('Model Loss over Epochs')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.grid(True)\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T04:04:23.868389Z","iopub.execute_input":"2025-11-11T04:04:23.868657Z","iopub.status.idle":"2025-11-11T04:04:24.248695Z","shell.execute_reply.started":"2025-11-11T04:04:23.868638Z","shell.execute_reply":"2025-11-11T04:04:24.247906Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport seaborn as sns\n\n# Set random seeds for reproducibility\nnp.random.seed(42)\ntf.random.set_seed(42)\n\ndef create_cnn_model(input_shape, num_classes):\n    \"\"\"Create and compile CNN model\"\"\"\n    model = Sequential([\n        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n        MaxPooling2D((2, 2)),\n        Dropout(0.25),\n        Conv2D(64, (3, 3), activation='relu'),\n        MaxPooling2D((2, 2)),\n        Dropout(0.25),\n        Conv2D(128, (3, 3), activation='relu'),\n        MaxPooling2D((2, 2)),\n        Dropout(0.25),\n        Flatten(),\n        Dense(128, activation='relu'),\n        Dropout(0.5),\n        Dense(num_classes, activation='softmax')\n    ])\n    \n    model.compile(optimizer='adam',\n                  loss='sparse_categorical_crossentropy',\n                  metrics=['accuracy'])\n    return model\n\n# Prepare data - assuming X_reshaped and y_encoded are already available\nX = X_reshaped  # Your mel-spectrogram data with shape (samples, height, width, 1)\ny = y_encoded   # Your encoded labels\n\nprint(f\"Total samples: {len(X)}\")\nprint(f\"Data shape: {X.shape}\")\nprint(f\"Number of classes: {len(np.unique(y))}\")\n\n# Initialize K-Fold Cross Validation\nn_splits = 10\nkfold = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n\n# Storage for results\nfold_results = []\nfold_histories = []\nall_predictions = []\nall_true_labels = []\n\nprint(\"\\n\" + \"=\"*70)\nprint(f\"Starting {n_splits}-Fold Cross Validation\")\nprint(\"=\"*70)\n\n# Perform K-Fold Cross Validation\nfor fold, (train_idx, val_idx) in enumerate(kfold.split(X, y), 1):\n    print(f\"\\n{'='*70}\")\n    print(f\"FOLD {fold}/{n_splits}\")\n    print(f\"{'='*70}\")\n    \n    # Split data\n    X_train_fold, X_val_fold = X[train_idx], X[val_idx]\n    y_train_fold, y_val_fold = y[train_idx], y[val_idx]\n    \n    print(f\"Training samples: {len(X_train_fold)}\")\n    print(f\"Validation samples: {len(X_val_fold)}\")\n    \n    # Create and train model\n    model = create_cnn_model(\n        input_shape=X_train_fold.shape[1:],\n        num_classes=len(np.unique(y))\n    )\n    \n    # Train model\n    history = model.fit(\n        X_train_fold, y_train_fold,\n        validation_data=(X_val_fold, y_val_fold),\n        epochs=50,\n        batch_size=32,\n        verbose=0  # Set to 1 to see training progress\n    )\n    \n    # Evaluate on validation set\n    val_loss, val_accuracy = model.evaluate(X_val_fold, y_val_fold, verbose=0)\n    \n    # Make predictions\n    y_pred_probs = model.predict(X_val_fold, verbose=0)\n    y_pred = np.argmax(y_pred_probs, axis=1)\n    \n    # Store results\n    fold_results.append({\n        'fold': fold,\n        'val_loss': val_loss,\n        'val_accuracy': val_accuracy,\n        'train_accuracy': history.history['accuracy'][-1],\n        'train_loss': history.history['loss'][-1]\n    })\n    fold_histories.append(history.history)\n    all_predictions.extend(y_pred)\n    all_true_labels.extend(y_val_fold)\n    \n    print(f\"\\nFold {fold} Results:\")\n    print(f\"  Training Accuracy: {fold_results[-1]['train_accuracy']*100:.2f}%\")\n    print(f\"  Validation Accuracy: {val_accuracy*100:.2f}%\")\n    print(f\"  Training Loss: {fold_results[-1]['train_loss']:.4f}\")\n    print(f\"  Validation Loss: {val_loss:.4f}\")\n\n# Calculate overall statistics\nprint(\"\\n\" + \"=\"*70)\nprint(\"CROSS VALIDATION SUMMARY\")\nprint(\"=\"*70)\n\nval_accuracies = [r['val_accuracy'] for r in fold_results]\ntrain_accuracies = [r['train_accuracy'] for r in fold_results]\n\nprint(f\"\\nValidation Accuracy Statistics:\")\nprint(f\"  Mean: {np.mean(val_accuracies)*100:.2f}%\")\nprint(f\"  Std:  {np.std(val_accuracies)*100:.2f}%\")\nprint(f\"  Min:  {np.min(val_accuracies)*100:.2f}%\")\nprint(f\"  Max:  {np.max(val_accuracies)*100:.2f}%\")\n\nprint(f\"\\nTraining Accuracy Statistics:\")\nprint(f\"  Mean: {np.mean(train_accuracies)*100:.2f}%\")\nprint(f\"  Std:  {np.std(train_accuracies)*100:.2f}%\")\n\nprint(f\"\\nOverfitting Gap (Train - Val):\")\nprint(f\"  Mean: {(np.mean(train_accuracies) - np.mean(val_accuracies))*100:.2f}%\")\n\n# Print individual fold results\nprint(\"\\n\" + \"-\"*70)\nprint(\"Individual Fold Results:\")\nprint(\"-\"*70)\nprint(f\"{'Fold':<8}{'Train Acc':<15}{'Val Acc':<15}{'Train Loss':<15}{'Val Loss':<15}\")\nprint(\"-\"*70)\nfor r in fold_results:\n    print(f\"{r['fold']:<8}{r['train_accuracy']*100:<14.2f}%{r['val_accuracy']*100:<14.2f}%\"\n          f\"{r['train_loss']:<15.4f}{r['val_loss']:<15.4f}\")\nprint(\"-\"*70)\n\n# Overall Classification Report\nprint(\"\\n\" + \"=\"*70)\nprint(\"OVERALL CLASSIFICATION REPORT (All Folds Combined)\")\nprint(\"=\"*70)\nprint(classification_report(all_true_labels, all_predictions, \n                           target_names=label_encoder.classes_))\n\n# ============= VISUALIZATION =============\n\n# 1. Box plot of fold accuracies\nfig, axes = plt.subplots(2, 2, figsize=(16, 12))\n\n# Plot 1: Box plot\naxes[0, 0].boxplot([train_accuracies, val_accuracies], \n                    labels=['Training', 'Validation'])\naxes[0, 0].set_ylabel('Accuracy')\naxes[0, 0].set_title('Accuracy Distribution Across Folds')\naxes[0, 0].grid(True, alpha=0.3)\naxes[0, 0].set_ylim([0, 1])\n\n# Plot 2: Fold-wise accuracy comparison\nfold_numbers = [r['fold'] for r in fold_results]\naxes[0, 1].plot(fold_numbers, train_accuracies, marker='o', \n                label='Training', linewidth=2, markersize=8)\naxes[0, 1].plot(fold_numbers, val_accuracies, marker='s', \n                label='Validation', linewidth=2, markersize=8)\naxes[0, 1].axhline(y=np.mean(val_accuracies), color='r', \n                   linestyle='--', label='Mean Val Acc', alpha=0.7)\naxes[0, 1].fill_between(fold_numbers, \n                        np.mean(val_accuracies) - np.std(val_accuracies),\n                        np.mean(val_accuracies) + np.std(val_accuracies),\n                        alpha=0.2, color='red')\naxes[0, 1].set_xlabel('Fold Number')\naxes[0, 1].set_ylabel('Accuracy')\naxes[0, 1].set_title('Accuracy Across Folds')\naxes[0, 1].legend()\naxes[0, 1].grid(True, alpha=0.3)\naxes[0, 1].set_xticks(fold_numbers)\n\n# Plot 3: Average training curves across all folds\nmax_epochs = len(fold_histories[0]['accuracy'])\navg_train_acc = np.mean([h['accuracy'] for h in fold_histories], axis=0)\navg_val_acc = np.mean([h['val_accuracy'] for h in fold_histories], axis=0)\nstd_train_acc = np.std([h['accuracy'] for h in fold_histories], axis=0)\nstd_val_acc = np.std([h['val_accuracy'] for h in fold_histories], axis=0)\n\nepochs = range(1, max_epochs + 1)\naxes[1, 0].plot(epochs, avg_train_acc, label='Avg Training', linewidth=2)\naxes[1, 0].plot(epochs, avg_val_acc, label='Avg Validation', linewidth=2)\naxes[1, 0].fill_between(epochs, \n                        avg_train_acc - std_train_acc,\n                        avg_train_acc + std_train_acc,\n                        alpha=0.2)\naxes[1, 0].fill_between(epochs, \n                        avg_val_acc - std_val_acc,\n                        avg_val_acc + std_val_acc,\n                        alpha=0.2)\naxes[1, 0].set_xlabel('Epoch')\naxes[1, 0].set_ylabel('Accuracy')\naxes[1, 0].set_title('Average Training Curves (±1 Std Dev)')\naxes[1, 0].legend()\naxes[1, 0].grid(True, alpha=0.3)\n\n# Plot 4: Confusion Matrix\ncm = confusion_matrix(all_true_labels, all_predictions)\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n            xticklabels=label_encoder.classes_,\n            yticklabels=label_encoder.classes_,\n            ax=axes[1, 1])\naxes[1, 1].set_xlabel('Predicted Label')\naxes[1, 1].set_ylabel('True Label')\naxes[1, 1].set_title('Overall Confusion Matrix (All Folds)')\n\nplt.tight_layout()\nplt.show()\n\n# Additional plot: Loss curves\nfig, ax = plt.subplots(1, 1, figsize=(10, 6))\navg_train_loss = np.mean([h['loss'] for h in fold_histories], axis=0)\navg_val_loss = np.mean([h['val_loss'] for h in fold_histories], axis=0)\nstd_train_loss = np.std([h['loss'] for h in fold_histories], axis=0)\nstd_val_loss = np.std([h['val_loss'] for h in fold_histories], axis=0)\n\nax.plot(epochs, avg_train_loss, label='Avg Training Loss', linewidth=2)\nax.plot(epochs, avg_val_loss, label='Avg Validation Loss', linewidth=2)\nax.fill_between(epochs, \n                avg_train_loss - std_train_loss,\n                avg_train_loss + std_train_loss,\n                alpha=0.2)\nax.fill_between(epochs, \n                avg_val_loss - std_val_loss,\n                avg_val_loss + std_val_loss,\n                alpha=0.2)\nax.set_xlabel('Epoch')\nax.set_ylabel('Loss')\nax.set_title('Average Loss Curves (±1 Std Dev)')\nax.legend()\nax.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.show()\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"K-Fold Cross Validation Complete!\")\nprint(\"=\"*70)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T04:46:35.028827Z","iopub.execute_input":"2025-11-11T04:46:35.029593Z","iopub.status.idle":"2025-11-11T04:55:52.656355Z","shell.execute_reply.started":"2025-11-11T04:46:35.029568Z","shell.execute_reply":"2025-11-11T04:55:52.655775Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# CNN + LSTM","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, LSTM, Dense, TimeDistributed, Reshape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T04:35:34.081101Z","iopub.execute_input":"2025-11-11T04:35:34.081888Z","iopub.status.idle":"2025-11-11T04:35:34.08556Z","shell.execute_reply.started":"2025-11-11T04:35:34.081861Z","shell.execute_reply":"2025-11-11T04:35:34.084695Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# CNN2D + LSTM Model\nmodel = Sequential([\n    # First Conv Block\n    Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=X_train.shape[1:]),\n    MaxPooling2D((2, 2)),\n    Dropout(0.25),\n    \n    # Second Conv Block\n    Conv2D(64, (3, 3), activation='relu', padding='same'),\n    MaxPooling2D((2, 2)),\n    Dropout(0.25),\n    \n    # Third Conv Block\n    Conv2D(128, (3, 3), activation='relu', padding='same'),\n    MaxPooling2D((2, 2)),\n    Dropout(0.25),\n    \n    # Reshape for LSTM: (batch, time_steps, features)\n    # After pooling layers, we have reduced dimensions\n    # Reshape to treat frequency bins as time steps\n    Reshape((-1, 128)),  # -1 will auto-calculate based on remaining dimensions\n    \n    # LSTM layers\n    LSTM(128, return_sequences=True, dropout=0.3),\n    LSTM(64, return_sequences=False, dropout=0.3),\n    \n    # Dense layers\n    Dense(64, activation='relu'),\n    Dropout(0.5),\n    Dense(len(label_encoder.classes_), activation='softmax')\n])\n\n# Compile the model\nmodel.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n\n# Print model summary\nmodel.summary()\n\n# Training\nhistory = model.fit(X_train, y_train,\n                    epochs=50,\n                    validation_data=(X_val, y_val),\n                    batch_size=32,\n                    verbose=1)\n\n# Evaluate on test set\nprint(\"\\n--- Evaluating CNN2D + LSTM Model on Test Set ---\")\ntest_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\nprint(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n\n# Predictions\ny_pred_probs = model.predict(X_test)\ny_pred = np.argmax(y_pred_probs, axis=1)\n\n# Classification report\nfrom sklearn.metrics import classification_report\nprint(classification_report(y_test, y_pred, target_names=label_encoder.classes_))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-11T04:35:35.179328Z","iopub.execute_input":"2025-11-11T04:35:35.180039Z","iopub.status.idle":"2025-11-11T04:37:19.47506Z","shell.execute_reply.started":"2025-11-11T04:35:35.180014Z","shell.execute_reply":"2025-11-11T04:37:19.474352Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# CNN + LSTM + Attention","metadata":{}},{"cell_type":"code","source":"# Remove unnecessary imports that are already done\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, LSTM, Dense, Reshape, Input, Multiply, Permute, RepeatVector, Lambda\nfrom tensorflow.keras import backend as K\n\n# Custom Attention Layer\nclass AttentionLayer(tf.keras.layers.Layer):\n    def __init__(self, **kwargs):\n        super(AttentionLayer, self).__init__(**kwargs)\n    \n    def build(self, input_shape):\n        self.W = self.add_weight(name='attention_weight', \n                                shape=(input_shape[-1], input_shape[-1]),\n                                initializer='glorot_uniform',\n                                trainable=True)\n        self.b = self.add_weight(name='attention_bias',\n                                shape=(input_shape[-1],),\n                                initializer='zeros',\n                                trainable=True)\n        super(AttentionLayer, self).build(input_shape)\n    \n    def call(self, x):\n        # x shape: (batch, time_steps, features)\n        e = K.tanh(K.dot(x, self.W) + self.b)\n        a = K.softmax(e, axis=1)\n        output = x * a\n        return K.sum(output, axis=1)\n    \n    def compute_output_shape(self, input_shape):\n        return (input_shape[0], input_shape[-1])\n\n# Building CNN2D + LSTM + Attention Model\ninput_layer = Input(shape=X_train.shape[1:])\n\n# First Conv Block\nx = Conv2D(32, (3, 3), activation='relu', padding='same')(input_layer)\nx = MaxPooling2D((2, 2))(x)\nx = Dropout(0.25)(x)\n\n# Second Conv Block\nx = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\nx = MaxPooling2D((2, 2))(x)\nx = Dropout(0.25)(x)\n\n# Third Conv Block\nx = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\nx = MaxPooling2D((2, 2))(x)\nx = Dropout(0.25)(x)\n\n# Reshape for LSTM\nx = Reshape((-1, 128))(x)\n\n# LSTM layers with return_sequences=True for attention\nx = LSTM(128, return_sequences=True, dropout=0.3)(x)\nx = LSTM(64, return_sequences=True, dropout=0.3)(x)\n\n# Attention Layer\nx = AttentionLayer()(x)\n\n# Dense layers\nx = Dense(64, activation='relu')(x)\nx = Dropout(0.5)(x)\noutput_layer = Dense(len(label_encoder.classes_), activation='softmax')(x)\n\n# Create model\nmodel = Model(inputs=input_layer, outputs=output_layer)\n\n# Compile the model\nmodel.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n\n# Print model summary\nmodel.summary()\n\n# Training\nhistory = model.fit(X_train, y_train,\n                    epochs=50,\n                    validation_data=(X_val, y_val),\n                    batch_size=32,\n                    verbose=1)\n\n# Evaluate on test set\nprint(\"\\n--- Evaluating CNN2D + LSTM + Attention Model on Test Set ---\")\ntest_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\nprint(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n\n# Predictions\ny_pred_probs = model.predict(X_test)\ny_pred = np.argmax(y_pred_probs, axis=1)\n\n# Classification report\nfrom sklearn.metrics import classification_report\nprint(classification_report(y_test, y_pred, target_names=label_encoder.classes_))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T03:40:48.127319Z","iopub.execute_input":"2025-11-10T03:40:48.12765Z","iopub.status.idle":"2025-11-10T03:42:25.751274Z","shell.execute_reply.started":"2025-11-10T03:40:48.127623Z","shell.execute_reply":"2025-11-10T03:42:25.750355Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}}]}